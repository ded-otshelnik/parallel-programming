# Задача 6. Параллельная технология MPI

## Содержание

## Технология MPI: классификация Флинна, модель параллелизма

Как говорилось в [теме про OpenMP](4rd-task.md#классификация-флинна-и-модель-параллелизма-mimd) системы MIMD делятся на два типа по типу организации оперативной памяти: **мультипроцессоры (с общей разделяемой памятью)** и **мультикомпьютеры (системы с разделяемой памятью)**. Если технология OpenMP относится к мультипроцессорам, то для параллелизма на мультикомпьютерах используется технология **MPI**.

Согласно официальному описанию, **MPI (Message-Passing Interface)** - это спецификация API библиотек для передачи данных. Стандарт MPI образуют процедуры передачи сообщений, а также процедуры ввода/вывода, использующие ресурсы параллелизма. Сама спецификация выпущена в 1994 году, на текущий момент актуальной версией спецификации является **MPI-4.0**, но далее будет описываться спецификация **[MPI-3.0](https://www.mpi-forum.org/docs/mpi-3.0/mpi30-report.pdf)**.

В рамках технологии MPI единая программа, написанная на высокоуровневом языке программирования (C/C++, Fortran, иногда даже Python), запускается на процессорах вычислительной системы, образуя, тем самым, **множество процессов**. Т.е. программа на MPI (в стадии выполнения) - множество параллельных взаимодействующих процессов. Каждый процесс обладает своим уникальным порядковым номером - **рангом**, что позволяет явно управлять действиями на различных вычислительных узлах. Обмен данными, требуемый для функционирования программы, осуществляется через механизм передачи сообщений путем вызова библиотечных функций, использующих возможности коммуникационных линий связи.

## Компиляция и запуск параллельной программы в среде MPI. Общая структура кода

Параллельная программа, использующая технологию MPI, должна быть скомпилирована и запущена особым образом, определяемым **реализацией стандарта**. Широко распространены две реализации: **OpenMPI** и **MPICH**. Далее будет рассмотрена реализация [OpenMPI](https://docs.open-mpi.org/en/v5.0.x/index.html):

+ Код параллельной программы представляется в виде файла с расширением ```.c``` и должен содержать в секции подключение заголовочных файлов ```#include <mpi.h>```.
+ Для запуска программы ***task.c*** требуется компилировать с помощью компилятора **mpicc** следующим образом:

```bash
mpicc task.c -o <output_name>
```

+ Запуск бинарного файла, полученного при компиляции, с **образованием** $N$ **процессов** осуществляется через команду **mpirun** следующим образом:

```bash
mpirun -n N <binary_file>
```

Инструкция как запускать параллельной программы в среде MPI на суперкомпьютере ВГУ представлена [здесь](supercomputer-guide.md).

Теперь рассмотрим важнейшие функции среды MPI, встречающиеся в **любой** параллельной программе. Сразу после объявления переменных в функции ***main*** должен следовать вызов функции ```MPI_Init()```, который инициализирует параллельную часть программы:

```c
int MPI_Init(int* argc, char*** argv)
```

где **argc** и **argv** - указатели на количество параметров командной строки и на массив указателей на строки соответственно. Параллельная часть программы завершается вызовом функции ```MPI_Finalize()```:

```c
int MPI_Finalize(void)
```

Вне параллельной области программы вызов функций MPI запрещен, кроме следующих четырех функций:

```c
int MPI_Get_version(int* version, int* subversion);
int MPI_Get_library_version(char* version, int* resultlen);
int MPI_Initialized(int* flag);
int MPI_Finalized(int* flag);
```

Важным понятием технологии является **коммуникатор**, под которым понимают группу процессов, которому поставлен в соответствие **дескриптор** (специальное описание объектов). Сразу после вызова функции *MPI_Init* формируется и становится доступным **глобальный коммуникатор** ```MPI_COMM_WORLD```. Такой коммуникатор содержит все доступные процессы.

Функция ```MPI_Comm_size()``` определяет число процессов, входящий в некоторый коммуникатор *comm*.

```c
int MPI_Comm_size(MPI_Comm comm, int* size);
```

В частности, вызов

```c
MPI_Comm_size(MPI_COMM_WORLD, &size);
```

сформирует число процессов, исполняющих программу, и запишет в переменную.

Для определения ранга процесса используется функция ```MPI_Comm_rank()```

```c
MPI_Comm_rank(MPI_COMM_WORLD, &rank);
```

Чтобы грамл

## Стандартный способ передачи сообщений

Под **сообщением** понимается вектор данных фиксированного типа. Некоторые доступные типы представлены [здесь](https://rookiehpc.org/mpi/docs/mpi_datatype/index.html).

Рассмотрим простейший способ передачи сообщения - **point-to-point communication (попарный обмен сообщениями между процессами)**. Для попарного обмена сообщениями используются две функции ```MPI_Send()``` и ```MPI_Recv()```:

```c
int MPI_Send(const void* buf, int count, MPI_Datatype datatype,
             int dest, int tag, MPI_Comm comm)
int MPI_Recv(void* buf, int count, MPI_Datatype datatype,
             int source, int tag, MPI_Comm comm, MPI_Status* status)
```

где *buf* - адрес буфера памяти с пересылаемым сообщением, *count* - длина сообщения, *datatype* - тип данных, *source* - ранг процесса-отправителя, *dest* - ранг процесса-получателя, *tag* - идентификатор сообщения, *comm* - коммуникатор, содержащий оба процесса, *status* - указатель на структуру, содержащую некоторую информацио о принятом сообщении.

Несмотря на свою простоту, неправильный вызов функций может привести к "тупику" (**deadlock**), когда оба процесса заблокированы из-за невозможности выполнить обмен сообщениями. Для преодоления подобной проблемы существует функция ```MPI_Sendrecv()```, которая объединяет действия двух функций.

```c
int MPI_Sendrecv(const void* sendbuf, int sendcount, MPI_Datatype sendtype, int dest, int sendtag,
                 void* recvbuf, int recvcount, MPI_Datatype recvtype, int source, int resvtag,
                 MPI_Comm comm, MPI_Status* status)
```

По умолчанию адреса *sendbuf* и *recvbuf* не должны совпадать. Если требуется изменить данные внутри одного буфера, то для этого используется функция ```MPI_Sendrecv_replace()```:

```c
int MPI_Sendrecv_replace(void* buf, int count, MPI_Datatype datatype,
                 int dest, int sendtag,
                 int source, int resvtag,
                 MPI_Comm comm, MPI_Status* status)
```

Если требуется, чтобы процесс получал от любого источника, отправлял любому получателю или принимал сообщения с любым тегом, то для 

## Задания

## Требования

## Варианты

1. f
2. f
3. f
4. f
5. f
6. f
7. f
8. f
9. f
10. f
11. f
12. f
13. f
14. f
